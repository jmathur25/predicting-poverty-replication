{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Using the CNN weights that were provided by the paper authors. These create a .npy file called `forward_feats.npy`, which should be placed in `setup_existing_model`.\n", "\n", "Run the script in `setup_existing_model` first"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import os"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["feats = np.load('setup_existing_model/forward_feats.npy')"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["ims = os.listdir('process_data/data/ims_malawi_2016/')"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>images</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>-14.408333_34.099999.png</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>-15.741666_34.491665999999995.png</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>-14.075_35.174999.png</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>-14.233332999999998_34.408332.png</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>-13.766666_33.116665999999995.png</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                              images\n", "0           -14.408333_34.099999.png\n", "1  -15.741666_34.491665999999995.png\n", "2              -14.075_35.174999.png\n", "3  -14.233332999999998_34.408332.png\n", "4  -13.766666_33.116665999999995.png"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["# since we passed our images to the model in this order, we know index 0\n", "# of this dataframe corresponds to index 0 of feats\n", "df_im_raw = pd.DataFrame.from_dict({'images': ims}); df_im_raw.head()"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/plain": ["(23464, 1)"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["df_im_raw.shape"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# this index corresponds to the row in \"forward_feats.npy\"\n", "df_im_raw['feat_index'] = np.arange(len(df_im_raw))"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["im_to_cons = pd.read_csv('process_data/mw_full_guide.csv')"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>im_lat</th>\n", "      <th>im_lon</th>\n", "      <th>clust_lat</th>\n", "      <th>clust_lon</th>\n", "      <th>nightlight</th>\n", "      <th>consumption</th>\n", "      <th>nightlight_bin</th>\n", "      <th>images</th>\n", "      <th>clust_num</th>\n", "      <th>images_renamed</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>-17.125000</td>\n", "      <td>35.174999</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.125_35.174999.png</td>\n", "      <td>0</td>\n", "      <td>-17.125_35.174999_0.png</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>-17.133333</td>\n", "      <td>35.174999</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.133333_35.174999.png</td>\n", "      <td>0</td>\n", "      <td>-17.133333_35.174999_0.png</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>-17.066666</td>\n", "      <td>35.191666</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.066666_35.191666.png</td>\n", "      <td>0</td>\n", "      <td>-17.066666_35.191666_0.png</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>-17.050000</td>\n", "      <td>35.199999</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.05_35.199999.png</td>\n", "      <td>0</td>\n", "      <td>-17.05_35.199999_0.png</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>-17.100000</td>\n", "      <td>35.199999</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.1_35.199999.png</td>\n", "      <td>0</td>\n", "      <td>-17.1_35.199999_0.png</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["      im_lat     im_lon  clust_lat  clust_lon  nightlight  consumption  \\\n", "0 -17.125000  35.174999  -17.09515  35.217213         0.0     2.039307   \n", "1 -17.133333  35.174999  -17.09515  35.217213         0.0     2.039307   \n", "2 -17.066666  35.191666  -17.09515  35.217213         0.0     2.039307   \n", "3 -17.050000  35.199999  -17.09515  35.217213         0.0     2.039307   \n", "4 -17.100000  35.199999  -17.09515  35.217213         0.0     2.039307   \n", "\n", "   nightlight_bin                    images  clust_num  \\\n", "0               1     -17.125_35.174999.png          0   \n", "1               1  -17.133333_35.174999.png          0   \n", "2               1  -17.066666_35.191666.png          0   \n", "3               1      -17.05_35.199999.png          0   \n", "4               1       -17.1_35.199999.png          0   \n", "\n", "               images_renamed  \n", "0     -17.125_35.174999_0.png  \n", "1  -17.133333_35.174999_0.png  \n", "2  -17.066666_35.191666_0.png  \n", "3      -17.05_35.199999_0.png  \n", "4       -17.1_35.199999_0.png  "]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["# notice we have duplicate images that we only pass once to the model to reduce runtime load\n", "# we need to add a column that tells us what index of feats to look at for that image\n", "im_to_cons.head()"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/plain": ["(36546, 10)"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["im_to_cons.shape"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# now we can merge\n", "im_to_cons = pd.merge(left=im_to_cons, right=df_im_raw, on='images')"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"data": {"text/plain": ["(36546, 11)"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["im_to_cons.shape # we shouldn't lose any rows"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>im_lat</th>\n", "      <th>im_lon</th>\n", "      <th>clust_lat</th>\n", "      <th>clust_lon</th>\n", "      <th>nightlight</th>\n", "      <th>consumption</th>\n", "      <th>nightlight_bin</th>\n", "      <th>images</th>\n", "      <th>clust_num</th>\n", "      <th>images_renamed</th>\n", "      <th>feat_index</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>-17.125000</td>\n", "      <td>35.174999</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.125_35.174999.png</td>\n", "      <td>0</td>\n", "      <td>-17.125_35.174999_0.png</td>\n", "      <td>9241</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>-17.133333</td>\n", "      <td>35.174999</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.133333_35.174999.png</td>\n", "      <td>0</td>\n", "      <td>-17.133333_35.174999_0.png</td>\n", "      <td>1462</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>-17.066666</td>\n", "      <td>35.191666</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.066666_35.191666.png</td>\n", "      <td>0</td>\n", "      <td>-17.066666_35.191666_0.png</td>\n", "      <td>7157</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>-17.050000</td>\n", "      <td>35.199999</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.05_35.199999.png</td>\n", "      <td>0</td>\n", "      <td>-17.05_35.199999_0.png</td>\n", "      <td>12701</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>-17.100000</td>\n", "      <td>35.199999</td>\n", "      <td>-17.09515</td>\n", "      <td>35.217213</td>\n", "      <td>0.0</td>\n", "      <td>2.039307</td>\n", "      <td>1</td>\n", "      <td>-17.1_35.199999.png</td>\n", "      <td>0</td>\n", "      <td>-17.1_35.199999_0.png</td>\n", "      <td>15357</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["      im_lat     im_lon  clust_lat  clust_lon  nightlight  consumption  \\\n", "0 -17.125000  35.174999  -17.09515  35.217213         0.0     2.039307   \n", "1 -17.133333  35.174999  -17.09515  35.217213         0.0     2.039307   \n", "2 -17.066666  35.191666  -17.09515  35.217213         0.0     2.039307   \n", "3 -17.050000  35.199999  -17.09515  35.217213         0.0     2.039307   \n", "4 -17.100000  35.199999  -17.09515  35.217213         0.0     2.039307   \n", "\n", "   nightlight_bin                    images  clust_num  \\\n", "0               1     -17.125_35.174999.png          0   \n", "1               1  -17.133333_35.174999.png          0   \n", "2               1  -17.066666_35.191666.png          0   \n", "3               1      -17.05_35.199999.png          0   \n", "4               1       -17.1_35.199999.png          0   \n", "\n", "               images_renamed  feat_index  \n", "0     -17.125_35.174999_0.png        9241  \n", "1  -17.133333_35.174999_0.png        1462  \n", "2  -17.066666_35.191666_0.png        7157  \n", "3      -17.05_35.199999_0.png       12701  \n", "4       -17.1_35.199999_0.png       15357  "]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["# we now have a dataframe that tells us what index to look at in forward_feats.npy for each image\n", "im_to_cons.head()"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["group = im_to_cons.groupby(['clust_lat', 'clust_lon'])"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"data": {"text/plain": ["778"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["num_clusts = len(group); num_clusts"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["x = np.zeros((num_clusts, 4096))\n", "y = []"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["# this goes through each cluster group and finds all images that are in the cluster\n", "# it aggregates the features for those images across the cluster\n", "for i, g in enumerate(group):\n", "    lat, long = g[0]\n", "    im_sub = im_to_cons[(im_to_cons['clust_lat'] == lat) & (im_to_cons['clust_lon'] == long)].reset_index(drop=True)\n", "    agg_feats = np.zeros((len(im_sub), 4096))\n", "    for j, d in im_sub.iterrows():\n", "        agg_feats[j,:] = feats[d.feat_index]\n", "    agg_feats = agg_feats.mean(axis=0) # averages the features across all images in the cluster\n", "    \n", "    x[i,:] = agg_feats\n", "    y.append(g[1]['consumption'].values[0])"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["y = np.array(y)\n", "y_log = np.log(y) # try predicting consumption and log consumption"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"data": {"text/plain": ["(778, 4096)"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": ["x.shape"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["# This is a bunch of code from the Jean et al Github that is modified to work with Python3 and our data\n", "\n", "import numpy as np\n", "import pandas as pd\n", "import random\n", "from scipy import stats\n", "from sklearn.decomposition import PCA\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.model_selection import KFold\n", "import sklearn.linear_model as linear_model\n", "import matplotlib.pyplot as plt\n", "from matplotlib.collections import EllipseCollection\n", "import seaborn as sns\n", "\n", "\n", "def predict_consumption(\n", "    X, y, k=5, k_inner=5, points=10,\n", "        alpha_low=1, alpha_high=5, margin=0.25):\n", "    \"\"\"\n", "    Plots predicted consumption\n", "    \"\"\"\n", "    y_hat, r2 = run_cv(X, y, k, k_inner, points, alpha_low, alpha_high)\n", "    return X, y, y_hat, r2\n", "\n", "\n", "def run_cv(X, y, k, k_inner, points, alpha_low, alpha_high, randomize=False):\n", "    \"\"\"\n", "    Runs nested cross-validation to make predictions and compute r-squared.\n", "    \"\"\"\n", "    alphas = np.logspace(alpha_low, alpha_high, points)\n", "    r2s = np.zeros((k,))\n", "    y_hat = np.zeros_like(y)\n", "    kf = KFold(n_splits=k, shuffle=True)\n", "    fold = 0\n", "    for train_idx, test_idx in kf.split(X):\n", "        r2s, y_hat, fold = evaluate_fold(\n", "            X, y, train_idx, test_idx, k_inner, alphas, r2s, y_hat, fold,\n", "            randomize)\n", "    return y_hat, r2s.mean()\n", "\n", "\n", "def scale_features(X_train, X_test):\n", "    \"\"\"\n", "    Scales features using StandardScaler.\n", "    \"\"\"\n", "    X_scaler = StandardScaler(with_mean=True, with_std=False)\n", "    X_train = X_scaler.fit_transform(X_train)\n", "    X_test = X_scaler.transform(X_test)\n", "    return X_train, X_test\n", "\n", "\n", "def train_and_predict_ridge(alpha, X_train, y_train, X_test):\n", "    \"\"\"\n", "    Trains ridge model and predicts test set.\n", "    \"\"\"\n", "    ridge = linear_model.Ridge(alpha)\n", "    ridge.fit(X_train, y_train)\n", "    y_hat = ridge.predict(X_test)\n", "    return y_hat\n", "\n", "\n", "def predict_inner_test_fold(X, y, y_hat, train_idx, test_idx, alpha):\n", "    \"\"\"\n", "    Predicts inner test fold.\n", "    \"\"\"\n", "    X_train, X_test = X[train_idx], X[test_idx]\n", "    y_train, y_test = y[train_idx], y[test_idx]\n", "    X_train, X_test = scale_features(X_train, X_test)\n", "    y_hat[test_idx] = train_and_predict_ridge(alpha, X_train, y_train, X_test)\n", "    return y_hat\n", "\n", "\n", "def find_best_alpha(X, y, k_inner, alphas):\n", "    \"\"\"\n", "    Finds the best alpha in an inner CV loop.\n", "    \"\"\"\n", "    kf = KFold(n_splits=k_inner, shuffle=True)\n", "    best_alpha = 0\n", "    best_r2 = 0\n", "    for idx, alpha in enumerate(alphas):\n", "        y_hat = np.zeros_like(y)\n", "        for train_idx, test_idx in kf.split(X):\n", "            y_hat = predict_inner_test_fold(\n", "                X, y, y_hat, train_idx, test_idx, alpha)\n", "        r2 = stats.pearsonr(y, y_hat)[0] ** 2\n", "        if r2 > best_r2:\n", "            best_alpha = alpha\n", "            best_r2 = r2\n", "    print('best alpha', best_alpha)\n", "    return best_alpha\n", "\n", "\n", "def evaluate_fold(\n", "    X, y, train_idx, test_idx, k_inner, alphas, r2s, y_hat, fold,\n", "        randomize):\n", "    \"\"\"\n", "    Evaluates one fold of outer CV.\n", "    \"\"\"\n", "    X_train, X_test = X[train_idx], X[test_idx]\n", "    y_train, y_test = y[train_idx], y[test_idx]\n", "    if randomize:\n", "        random.shuffle(y_train)\n", "    best_alpha = find_best_alpha(X_train, y_train, k_inner, alphas)\n", "    X_train, X_test = scale_features(X_train, X_test)\n", "    y_test_hat = train_and_predict_ridge(best_alpha, X_train, y_train, X_test)\n", "    r2 = stats.pearsonr(y_test, y_test_hat)[0] ** 2\n", "    r2s[fold] = r2\n", "    y_hat[test_idx] = y_test_hat\n", "    return r2s, y_hat, fold + 1"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["best alpha 10.0\n", "best alpha 10.0\n", "best alpha 27.825594022071243\n", "best alpha 10.0\n", "best alpha 10.0\n"]}, {"data": {"text/plain": ["0.1699185557179395"]}, "execution_count": 20, "metadata": {}, "output_type": "execute_result"}], "source": ["_, _, _, r2 = predict_consumption(x, y_log)\n", "r2"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["best alpha 10.0\n", "best alpha 10.0\n", "best alpha 10.0\n", "best alpha 10.0\n", "best alpha 10.0\n"]}, {"data": {"text/plain": ["0.10141235730129028"]}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": ["_, _, _, r2 = predict_consumption(x, y)\n", "r2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<strong> Important Note </strong> <br>\n", "If you read the original paper, you'll see that the paper's consumption prediction has r^2 of 0.33 or higher. Why is ours so much lower using their weights? Well, here we are using (free) 2019 images to predict their 2016 consumption values. Ideally, we should download 2016 images, and if we want to follow the paper exactly, we download 2013 images (for Malawi at least). However, this doesn't explain why if I train the model from scratch, it matches the paper's performance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 2}